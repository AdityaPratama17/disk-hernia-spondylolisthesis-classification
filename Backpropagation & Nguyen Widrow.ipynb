{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCvEKlVwofzk"
   },
   "source": [
    "IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KulfoJn6RFOM"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAGr6nVKoilD"
   },
   "source": [
    "PREPROCESSING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UUJk05pKRNE6"
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "dataset = pd.read_csv('dataset-vertebral column.csv')\n",
    "\n",
    "# set data & label\n",
    "X = dataset.iloc[:, :-1].values # menampung data\n",
    "Y = dataset.iloc[:, -1].values # menampung label\n",
    "\n",
    "# MinMax Normalization\n",
    "X = minmax_scale(X)\n",
    "\n",
    "# One-hot Encoding\n",
    "Y_encode = []\n",
    "for index,i in enumerate(Y.tolist()):\n",
    "  if i == 1: Y_encode.append([1,0,0])\n",
    "  if i == 2: Y_encode.append([0,1,0])\n",
    "  if i == 3: Y_encode.append([0,0,1])\n",
    "\n",
    "# Split training & testing data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y_encode, test_size=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Bcswu_3ooJv"
   },
   "source": [
    "TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_FwnAPB2RPzr"
   },
   "outputs": [],
   "source": [
    "# Sigmoid activation\n",
    "def sigmoid(x):\n",
    "  return 1/(1 + np.exp(-x))\n",
    "sig = np.vectorize(sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Wi2S6IdVRisF"
   },
   "outputs": [],
   "source": [
    "# Nguyen-Widraw\n",
    "def nguyen_widrow(n,p):\n",
    "  # n = 6 #input\n",
    "  # p = 5 #hidden\n",
    "\n",
    "  weight = np.random.uniform(low=-5, high=5, size=(p,n))\n",
    "  beta = .7*(p**(1/n))\n",
    "  bias = np.random.uniform(low=-beta, high=beta, size=p)\n",
    "  norm_hidden = []\n",
    "\n",
    "  for i in range(p):\n",
    "    jum = 0\n",
    "    for j in range(n):\n",
    "      jum += weight[i][j]**2\n",
    "    norm_hidden.append(jum**(1/2))\n",
    "  \n",
    "  for i in range(p):\n",
    "    for j in range(n):\n",
    "      weight[i][j] = beta * weight[i][j] / norm_hidden[i]\n",
    "\n",
    "  return weight, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cZ48UaG7RTr5"
   },
   "outputs": [],
   "source": [
    "def model_fit(hidden_layer, input_layer, output_layer, x_train, y_train, epoch, nw):\n",
    "  loss_values = []\n",
    "  acc_values = []\n",
    "\n",
    "  # inisialisasi bobot dan bias: hidden layer\n",
    "  if nw:\n",
    "    w_hidden, b_hidden = nguyen_widrow(input_layer,hidden_layer)\n",
    "  else:\n",
    "    # w_hidden = np.random.uniform(low=-5, high=5, size=(hidden_layer,input_layer))\n",
    "    # b_hidden = np.random.uniform(low=-5, high=5, size=hidden_layer)\n",
    "    w_hidden = np.random.uniform(low=-1, high=1, size=(hidden_layer,input_layer))\n",
    "    b_hidden = np.random.uniform(low=-1, high=1, size=hidden_layer)\n",
    "\n",
    "  # inisialisasi bobot dan bias: Output layer\n",
    "  w_output = np.random.uniform(low=-5, high=5, size=(output_layer,hidden_layer))\n",
    "  b_output = np.random.uniform(low=-5, high=5, size=output_layer)\n",
    "  # w_output, b_output = nguyen_widrow(hidden_layer,output_layer)\n",
    "\n",
    "  for i in range(epoch):\n",
    "    mse = 0\n",
    "    acc = 0\n",
    "    for index,data in enumerate(x_train):\n",
    "      # === FEEDFOWARD ===\n",
    "      # ---- feedfoward: hidden layer\n",
    "      o_hidden = np.matmul(w_hidden, data) + b_hidden\n",
    "      o_hidden = sig(o_hidden)\n",
    "      # ---- feedfoward: output layer\n",
    "      o_output = np.matmul(w_output, o_hidden) + b_output\n",
    "      o_output = sig(o_output)\n",
    "\n",
    "      # === BACKPROPAGATION ===\n",
    "      # ---- error: output layer\n",
    "      e_output = (y_train[index]-o_output) * o_output * (1 - o_output)\n",
    "      # ---- delta bobot: output layer\n",
    "      deltaW_output = lr * (e_output * o_hidden[np.newaxis].T)\n",
    "      # ---- delta bias: output layer\n",
    "      deltaB_output = lr * e_output\n",
    "\n",
    "      # ---- error: hidden layer\n",
    "      e_hidden = (np.matmul(np.array(w_output).T.tolist(), e_output)) * o_hidden * (1 - o_hidden)\n",
    "      # ---- delta bobot: hidden layer\n",
    "      deltaW_hidden = lr * (e_hidden * np.array(data)[np.newaxis].T)\n",
    "      # ---- delta bias: hidden layer\n",
    "      deltaB_hidden = lr * e_hidden\n",
    "\n",
    "      # ---- update bobot: output layer\n",
    "      w_output = w_output + deltaW_output.transpose()\n",
    "      # ---- update bias: output layer\n",
    "      b_output = b_output + deltaB_output\n",
    "\n",
    "      # ---- update bobot: hidden layer\n",
    "      w_hidden = w_hidden + deltaW_hidden.transpose()\n",
    "      # ---- update bias: hidden layer\n",
    "      b_hidden = b_hidden + deltaB_hidden\n",
    "\n",
    "      mse += sum((y_train[index]-o_output) ** 2)\n",
    "      acc += sum(np.absolute(y_train[index]-o_output.round()))\n",
    "    \n",
    "    mse /= len(x_train)\n",
    "    acc = 1 - (acc/len(y_train))\n",
    "    if mse < 0.01: break\n",
    "    else:\n",
    "      loss_values.append(mse)\n",
    "      acc_values.append(acc)\n",
    "      # print(\"Epoch:\",i,\" | loss :\",mse,\" | accuracy :\",acc)\n",
    "      print(\"Epoch:\",i,\" | loss :\",mse)\n",
    "  \n",
    "  return w_hidden, b_hidden, w_output, b_output, loss_values, acc_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "etRFMxX2oq8T"
   },
   "source": [
    "TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7GOfMrp-RU36"
   },
   "outputs": [],
   "source": [
    "def predict(x_test, w_hidden, b_hidden, w_output, b_output):\n",
    "  acc = 0\n",
    "  o_predict = []\n",
    "  o_predict2 = []\n",
    "  for index,data in enumerate(x_test):\n",
    "    # === FEEDFOWARD ===\n",
    "    # ---- feedfoward: hidden layer\n",
    "    o_hidden = sig(np.matmul(w_hidden, data) + b_hidden)\n",
    "    # ---- feedfoward: output layer\n",
    "    o_output = sig(np.matmul(w_output, o_hidden) + b_output)\n",
    "    o_predict.append((np.round(o_output)).tolist())\n",
    "    o_predict2.append(o_output)\n",
    "\n",
    "    if y_test[index]==(np.round(o_output)).tolist(): acc+=1\n",
    "  # print('predict : ',acc/len(x_test))\n",
    "\n",
    "  return acc/len(x_test), o_predict, o_predict2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XAU8NukjotTb"
   },
   "source": [
    "TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AMSnnIHQRXgS",
    "outputId": "96a97e74-630c-4b81-a00d-0951c50abc2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0  | loss : 0.6398380229186149\n",
      "Epoch: 1  | loss : 0.5490864897693623\n",
      "Epoch: 2  | loss : 0.5226242404375976\n",
      "Epoch: 3  | loss : 0.5080799813471569\n",
      "Epoch: 4  | loss : 0.4979018230110521\n",
      "Epoch: 5  | loss : 0.48986839311149344\n",
      "Epoch: 6  | loss : 0.4829916262250095\n",
      "Epoch: 7  | loss : 0.47649628513759507\n",
      "Epoch: 8  | loss : 0.46849032281332603\n",
      "Epoch: 9  | loss : 0.43644450344925423\n",
      "Epoch: 10  | loss : 0.4030118208227506\n",
      "Epoch: 11  | loss : 0.3912789554304599\n",
      "Epoch: 12  | loss : 0.3819920220666057\n",
      "Epoch: 13  | loss : 0.3742061324818637\n",
      "Epoch: 14  | loss : 0.36752713029702133\n",
      "Epoch: 15  | loss : 0.36168334284441866\n",
      "Epoch: 16  | loss : 0.3564725488434364\n",
      "Epoch: 17  | loss : 0.3517445427185466\n",
      "Epoch: 18  | loss : 0.347386500036448\n",
      "Epoch: 19  | loss : 0.343311903134188\n",
      "Epoch: 20  | loss : 0.33945313019166484\n",
      "Epoch: 21  | loss : 0.33575662041925175\n",
      "Epoch: 22  | loss : 0.33217963623141444\n",
      "Epoch: 23  | loss : 0.32868802984037493\n",
      "Epoch: 24  | loss : 0.32525469866453083\n",
      "Epoch: 25  | loss : 0.32185856086183096\n",
      "Epoch: 26  | loss : 0.3184839473207135\n",
      "Epoch: 27  | loss : 0.31512031989229944\n",
      "Epoch: 28  | loss : 0.3117621972431565\n",
      "Epoch: 29  | loss : 0.3084091090268873\n",
      "Epoch: 30  | loss : 0.3050653390191444\n",
      "Epoch: 31  | loss : 0.3017392213244716\n",
      "Epoch: 32  | loss : 0.298441881301249\n",
      "Epoch: 33  | loss : 0.2951855542177421\n",
      "Epoch: 34  | loss : 0.2919818366146266\n",
      "Epoch: 35  | loss : 0.28884022646765906\n",
      "Epoch: 36  | loss : 0.28576703805906306\n",
      "Epoch: 37  | loss : 0.28276456006753814\n",
      "Epoch: 38  | loss : 0.2798306236329333\n",
      "Epoch: 39  | loss : 0.2769593733590607\n",
      "Epoch: 40  | loss : 0.27414394679699733\n",
      "Epoch: 41  | loss : 0.27138043046551696\n",
      "Epoch: 42  | loss : 0.2686710649992866\n",
      "Epoch: 43  | loss : 0.2660248676429085\n",
      "Epoch: 44  | loss : 0.2634555184753384\n",
      "Epoch: 45  | loss : 0.2609778786557048\n",
      "Epoch: 46  | loss : 0.2586047812618243\n",
      "Epoch: 47  | loss : 0.2563450475389758\n",
      "Epoch: 48  | loss : 0.25420285465820325\n",
      "Epoch: 49  | loss : 0.2521780976824601\n",
      "Epoch: 50  | loss : 0.250267276385301\n",
      "Epoch: 51  | loss : 0.24846453120865195\n",
      "Epoch: 52  | loss : 0.24676260022537433\n",
      "Epoch: 53  | loss : 0.24515359326748906\n",
      "Epoch: 54  | loss : 0.243629560038436\n",
      "Epoch: 55  | loss : 0.24218287184987497\n",
      "Epoch: 56  | loss : 0.2408064539441003\n",
      "Epoch: 57  | loss : 0.23949390795075348\n",
      "Epoch: 58  | loss : 0.2382395592573237\n",
      "Epoch: 59  | loss : 0.23703845642607735\n",
      "Epoch: 60  | loss : 0.23588634179414547\n",
      "Epoch: 61  | loss : 0.23477960538793435\n",
      "Epoch: 62  | loss : 0.23371522889633095\n",
      "Epoch: 63  | loss : 0.23269072286481504\n",
      "Epoch: 64  | loss : 0.23170405838812133\n",
      "Epoch: 65  | loss : 0.23075359409025464\n",
      "Epoch: 66  | loss : 0.22983799966209056\n",
      "Epoch: 67  | loss : 0.22895617819501882\n",
      "Epoch: 68  | loss : 0.22810719052958217\n",
      "Epoch: 69  | loss : 0.22729018543721402\n",
      "Epoch: 70  | loss : 0.22650433942517606\n",
      "Epoch: 71  | loss : 0.22574880924353496\n",
      "Epoch: 72  | loss : 0.22502269890929094\n",
      "Epoch: 73  | loss : 0.22432504151303462\n",
      "Epoch: 74  | loss : 0.2236547945549555\n",
      "Epoch: 75  | loss : 0.2230108463491227\n",
      "Epoch: 76  | loss : 0.22239203031439045\n",
      "Epoch: 77  | loss : 0.22179714378554663\n",
      "Epoch: 78  | loss : 0.22122496826307045\n",
      "Epoch: 79  | loss : 0.22067428863233943\n",
      "Epoch: 80  | loss : 0.2201439096545891\n",
      "Epoch: 81  | loss : 0.21963266880882593\n",
      "Epoch: 82  | loss : 0.21913944523428122\n",
      "Epoch: 83  | loss : 0.21866316502600983\n",
      "Epoch: 84  | loss : 0.21820280345659623\n",
      "Epoch: 85  | loss : 0.21775738485233437\n",
      "Epoch: 86  | loss : 0.2173259808779397\n",
      "Epoch: 87  | loss : 0.21690770792019137\n",
      "Epoch: 88  | loss : 0.2165017241447673\n",
      "Epoch: 89  | loss : 0.2161072266612412\n",
      "Epoch: 90  | loss : 0.2157234490896459\n",
      "Epoch: 91  | loss : 0.21534965969167683\n",
      "Epoch: 92  | loss : 0.2149851601182369\n",
      "Epoch: 93  | loss : 0.2146292847364669\n",
      "Epoch: 94  | loss : 0.2142814004347002\n",
      "Epoch: 95  | loss : 0.21394090676221306\n",
      "Epoch: 96  | loss : 0.21360723624021222\n",
      "Epoch: 97  | loss : 0.2132798546783285\n",
      "Epoch: 98  | loss : 0.21295826134351592\n",
      "Epoch: 99  | loss : 0.2126419888520552\n",
      "Epoch: 100  | loss : 0.21233060268664145\n",
      "Epoch: 101  | loss : 0.2120237002760164\n",
      "Epoch: 102  | loss : 0.2117209096114149\n",
      "Epoch: 103  | loss : 0.21142188740995546\n",
      "Epoch: 104  | loss : 0.21112631686829383\n",
      "Epoch: 105  | loss : 0.21083390507912142\n",
      "Epoch: 106  | loss : 0.2105443802075545\n",
      "Epoch: 107  | loss : 0.21025748854338713\n",
      "Epoch: 108  | loss : 0.2099729915580487\n",
      "Epoch: 109  | loss : 0.2096906631012095\n",
      "Epoch: 110  | loss : 0.20941028687084517\n",
      "Epoch: 111  | loss : 0.2091316542816007\n",
      "Epoch: 112  | loss : 0.2088545628392868\n",
      "Epoch: 113  | loss : 0.20857881510440315\n",
      "Epoch: 114  | loss : 0.20830421829554924\n",
      "Epoch: 115  | loss : 0.20803058454597645\n",
      "Epoch: 116  | loss : 0.2077577317857645\n",
      "Epoch: 117  | loss : 0.20748548518124543\n",
      "Epoch: 118  | loss : 0.20721367902587734\n",
      "Epoch: 119  | loss : 0.20694215894632892\n",
      "Epoch: 120  | loss : 0.20667078426712687\n",
      "Epoch: 121  | loss : 0.20639943036897243\n",
      "Epoch: 122  | loss : 0.20612799088050496\n",
      "Epoch: 123  | loss : 0.20585637956023561\n",
      "Epoch: 124  | loss : 0.20558453175249586\n",
      "Epoch: 125  | loss : 0.20531240533544512\n",
      "Epoch: 126  | loss : 0.20503998111675534\n",
      "Epoch: 127  | loss : 0.20476726266983494\n",
      "Epoch: 128  | loss : 0.20449427563711994\n",
      "Epoch: 129  | loss : 0.20422106655464278\n",
      "Epoch: 130  | loss : 0.20394770127237305\n",
      "Epoch: 131  | loss : 0.20367426305729075\n",
      "Epoch: 132  | loss : 0.20340085047124204\n",
      "Epoch: 133  | loss : 0.20312757511430865\n",
      "Epoch: 134  | loss : 0.20285455931810667\n",
      "Epoch: 135  | loss : 0.2025819338634937\n",
      "Epoch: 136  | loss : 0.20230983578502656\n",
      "Epoch: 137  | loss : 0.20203840631130557\n",
      "Epoch: 138  | loss : 0.20176778897704722\n",
      "Epoch: 139  | loss : 0.20149812793002594\n",
      "Epoch: 140  | loss : 0.2012295664444814\n",
      "Epoch: 141  | loss : 0.20096224564253504\n",
      "Epoch: 142  | loss : 0.2006963034168611\n",
      "Epoch: 143  | loss : 0.20043187354145142\n",
      "Epoch: 144  | loss : 0.20016908495284386\n",
      "Epoch: 145  | loss : 0.1999080611816229\n",
      "Epoch: 146  | loss : 0.19964891991318628\n",
      "Epoch: 147  | loss : 0.1993917726574845\n",
      "Epoch: 148  | loss : 0.19913672450936434\n",
      "Epoch: 149  | loss : 0.19888387398388432\n",
      "Epoch: 150  | loss : 0.19863331291413489\n",
      "Epoch: 151  | loss : 0.19838512640226263\n",
      "Epoch: 152  | loss : 0.19813939281723092\n",
      "Epoch: 153  | loss : 0.19789618383505958\n",
      "Epoch: 154  | loss : 0.1976555645187256\n",
      "Epoch: 155  | loss : 0.1974175934354987\n",
      "Epoch: 156  | loss : 0.19718232280932407\n",
      "Epoch: 157  | loss : 0.19694979870507037\n",
      "Epoch: 158  | loss : 0.1967200612402829\n",
      "Epoch: 159  | loss : 0.1964931448187679\n",
      "Epoch: 160  | loss : 0.19626907837911697\n",
      "Epoch: 161  | loss : 0.19604788565039993\n",
      "Epoch: 162  | loss : 0.19582958540685008\n",
      "Epoch: 163  | loss : 0.1956141917135356\n",
      "Epoch: 164  | loss : 0.19540171415573734\n",
      "Epoch: 165  | loss : 0.19519215804603238\n",
      "Epoch: 166  | loss : 0.1949855246047269\n",
      "Epoch: 167  | loss : 0.19478181111122633\n",
      "Epoch: 168  | loss : 0.1945810110259491\n",
      "Epoch: 169  | loss : 0.1943831140843559\n",
      "Epoch: 170  | loss : 0.1941881063664449\n",
      "Epoch: 171  | loss : 0.19399597034651497\n",
      "Epoch: 172  | loss : 0.19380668492909708\n",
      "Epoch: 173  | loss : 0.1936202254776006\n",
      "Epoch: 174  | loss : 0.19343656384247715\n",
      "Epoch: 175  | loss : 0.1932556683955374\n",
      "Epoch: 176  | loss : 0.1930775040765575\n",
      "Epoch: 177  | loss : 0.19290203245751913\n",
      "Epoch: 178  | loss : 0.19272921182881642\n",
      "Epoch: 179  | loss : 0.19255899731062584\n",
      "Epoch: 180  | loss : 0.1923913409914179\n",
      "Epoch: 181  | loss : 0.192226192094378\n",
      "Epoch: 182  | loss : 0.19206349717135018\n",
      "Epoch: 183  | loss : 0.19190320032286187\n",
      "Epoch: 184  | loss : 0.19174524344188193\n",
      "Epoch: 185  | loss : 0.19158956647820244\n",
      "Epoch: 186  | loss : 0.19143610771977868\n",
      "Epoch: 187  | loss : 0.1912848040869577\n",
      "Epoch: 188  | loss : 0.19113559143530967\n",
      "Epoch: 189  | loss : 0.19098840486272625\n",
      "Epoch: 190  | loss : 0.19084317901653958\n",
      "Epoch: 191  | loss : 0.19069984839662188\n",
      "Epoch: 192  | loss : 0.19055834765074856\n",
      "Epoch: 193  | loss : 0.1904186118588878\n",
      "Epoch: 194  | loss : 0.1902805768035233\n",
      "Epoch: 195  | loss : 0.19014417922358337\n",
      "Epoch: 196  | loss : 0.1900093570500269\n",
      "Epoch: 197  | loss : 0.18987604962161117\n",
      "Epoch: 198  | loss : 0.1897441978798021\n",
      "Epoch: 199  | loss : 0.18961374454222177\n",
      "Epoch: 200  | loss : 0.18948463425438813\n",
      "Epoch: 201  | loss : 0.189356813719843\n",
      "Epoch: 202  | loss : 0.18923023180904658\n",
      "Epoch: 203  | loss : 0.18910483964765396\n",
      "Epoch: 204  | loss : 0.18898059068499162\n",
      "Epoch: 205  | loss : 0.18885744074369007\n",
      "Epoch: 206  | loss : 0.18873534805155487\n",
      "Epoch: 207  | loss : 0.1886142732568315\n",
      "Epoch: 208  | loss : 0.1884941794280692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 209  | loss : 0.18837503203981626\n",
      "Epoch: 210  | loss : 0.18825679894537886\n",
      "Epoch: 211  | loss : 0.1881394503378679\n",
      "Epoch: 212  | loss : 0.18802295870072258\n",
      "Epoch: 213  | loss : 0.18790729874887577\n",
      "Epoch: 214  | loss : 0.18779244736166606\n",
      "Epoch: 215  | loss : 0.18767838350856658\n",
      "Epoch: 216  | loss : 0.18756508816873882\n",
      "Epoch: 217  | loss : 0.187452544245369\n",
      "Epoch: 218  | loss : 0.18734073647568697\n",
      "Epoch: 219  | loss : 0.18722965133751626\n",
      "Epoch: 220  | loss : 0.18711927695314448\n",
      "Epoch: 221  | loss : 0.1870096029912578\n",
      "Epoch: 222  | loss : 0.1869006205676198\n",
      "Epoch: 223  | loss : 0.1867923221451408\n",
      "Epoch: 224  | loss : 0.18668470143391971\n",
      "Epoch: 225  | loss : 0.18657775329180337\n",
      "Epoch: 226  | loss : 0.18647147362596453\n",
      "Epoch: 227  | loss : 0.18636585929594585\n",
      "Epoch: 228  | loss : 0.18626090801858633\n",
      "Epoch: 229  | loss : 0.18615661827520225\n",
      "Epoch: 230  | loss : 0.18605298922135036\n",
      "Epoch: 231  | loss : 0.18595002059947585\n",
      "Epoch: 232  | loss : 0.1858477126546932\n",
      "Epoch: 233  | loss : 0.18574606605393407\n",
      "Epoch: 234  | loss : 0.18564508180864278\n",
      "Epoch: 235  | loss : 0.18554476120118402\n",
      "Epoch: 236  | loss : 0.18544510571508202\n",
      "Epoch: 237  | loss : 0.18534611696919706\n",
      "Epoch: 238  | loss : 0.18524779665589935\n",
      "Epoch: 239  | loss : 0.18515014648329195\n",
      "Epoch: 240  | loss : 0.1850531681214916\n",
      "Epoch: 241  | loss : 0.1849568631529721\n",
      "Epoch: 242  | loss : 0.18486123302693466\n",
      "Epoch: 243  | loss : 0.18476627901766393\n",
      "Epoch: 244  | loss : 0.18467200218680424\n",
      "Epoch: 245  | loss : 0.18457840334946976\n",
      "Epoch: 246  | loss : 0.18448548304409904\n",
      "Epoch: 247  | loss : 0.18439324150593708\n",
      "Epoch: 248  | loss : 0.18430167864402935\n",
      "Epoch: 249  | loss : 0.18421079402158855\n",
      "Epoch: 250  | loss : 0.18412058683960217\n",
      "Epoch: 251  | loss : 0.18403105592352487\n",
      "Epoch: 252  | loss : 0.18394219971290737\n",
      "Epoch: 253  | loss : 0.1838540162538029\n",
      "Epoch: 254  | loss : 0.1837665031937889\n",
      "Epoch: 255  | loss : 0.18367965777944234\n",
      "Epoch: 256  | loss : 0.18359347685610478\n",
      "Epoch: 257  | loss : 0.18350795686977558\n",
      "Epoch: 258  | loss : 0.18342309387096636\n",
      "Epoch: 259  | loss : 0.18333888352036387\n",
      "Epoch: 260  | loss : 0.18325532109614107\n",
      "Epoch: 261  | loss : 0.18317240150276062\n",
      "Epoch: 262  | loss : 0.1830901192811274\n",
      "Epoch: 263  | loss : 0.18300846861994383\n",
      "Epoch: 264  | loss : 0.18292744336812858\n",
      "Epoch: 265  | loss : 0.18284703704816777\n",
      "Epoch: 266  | loss : 0.1827672428702695\n",
      "Epoch: 267  | loss : 0.1826880537472063\n",
      "Epoch: 268  | loss : 0.18260946230972303\n",
      "Epoch: 269  | loss : 0.18253146092241337\n",
      "Epoch: 270  | loss : 0.18245404169995488\n",
      "Epoch: 271  | loss : 0.18237719652361342\n",
      "Epoch: 272  | loss : 0.18230091705792867\n",
      "Epoch: 273  | loss : 0.18222519476749982\n",
      "Epoch: 274  | loss : 0.1821500209337938\n",
      "Epoch: 275  | loss : 0.18207538667191234\n",
      "Epoch: 276  | loss : 0.18200128294725187\n",
      "Epoch: 277  | loss : 0.1819277005920002\n",
      "Epoch: 278  | loss : 0.18185463032142218\n",
      "Epoch: 279  | loss : 0.18178206274988015\n",
      "Epoch: 280  | loss : 0.18170998840656058\n",
      "Epoch: 281  | loss : 0.1816383977508606\n",
      "Epoch: 282  | loss : 0.18156728118740809\n",
      "Epoch: 283  | loss : 0.18149662908068817\n",
      "Epoch: 284  | loss : 0.18142643176925188\n",
      "Epoch: 285  | loss : 0.18135667957948665\n",
      "Epoch: 286  | loss : 0.1812873628389374\n",
      "Epoch: 287  | loss : 0.18121847188915996\n",
      "Epoch: 288  | loss : 0.18114999709810023\n",
      "Epoch: 289  | loss : 0.18108192887199287\n",
      "Epoch: 290  | loss : 0.18101425766677165\n",
      "Epoch: 291  | loss : 0.18094697399899473\n",
      "Epoch: 292  | loss : 0.1808800684562769\n",
      "Epoch: 293  | loss : 0.18081353170723924\n",
      "Epoch: 294  | loss : 0.18074735451097151\n",
      "Epoch: 295  | loss : 0.18068152772601972\n",
      "Epoch: 296  | loss : 0.18061604231889633\n",
      "Epoch: 297  | loss : 0.1805508893721298\n",
      "Epoch: 298  | loss : 0.1804860600918513\n",
      "Epoch: 299  | loss : 0.18042154581493902\n",
      "Epoch: 300  | loss : 0.18035733801571885\n",
      "Epoch: 301  | loss : 0.1802934283122403\n",
      "Epoch: 302  | loss : 0.1802298084721329\n",
      "Epoch: 303  | loss : 0.1801664704180596\n",
      "Epoch: 304  | loss : 0.18010340623277152\n",
      "Epoch: 305  | loss : 0.1800406081637843\n",
      "Epoch: 306  | loss : 0.17997806862768187\n",
      "Epoch: 307  | loss : 0.17991578021406215\n",
      "Epoch: 308  | loss : 0.1798537356891362\n",
      "Epoch: 309  | loss : 0.1797919279989952\n",
      "Epoch: 310  | loss : 0.17973035027255088\n",
      "Epoch: 311  | loss : 0.1796689958241711\n",
      "Epoch: 312  | loss : 0.17960785815601313\n",
      "Epoch: 313  | loss : 0.17954693096007016\n",
      "Epoch: 314  | loss : 0.17948620811994517\n",
      "Epoch: 315  | loss : 0.17942568371235562\n",
      "Epoch: 316  | loss : 0.17936535200838902\n",
      "Epoch: 317  | loss : 0.17930520747451117\n",
      "Epoch: 318  | loss : 0.1792452447733445\n",
      "Epoch: 319  | loss : 0.17918545876421907\n",
      "Epoch: 320  | loss : 0.1791258445035157\n",
      "Epoch: 321  | loss : 0.1790663972447983\n",
      "Epoch: 322  | loss : 0.179007112438754\n",
      "Epoch: 323  | loss : 0.1789479857329449\n",
      "Epoch: 324  | loss : 0.1788890129713798\n",
      "Epoch: 325  | loss : 0.17883019019391588\n",
      "Epoch: 326  | loss : 0.1787715136354933\n",
      "Epoch: 327  | loss : 0.17871297972521494\n",
      "Epoch: 328  | loss : 0.17865458508527324\n",
      "Epoch: 329  | loss : 0.17859632652973367\n",
      "Epoch: 330  | loss : 0.1785382010631772\n",
      "Epoch: 331  | loss : 0.17848020587921148\n",
      "Epoch: 332  | loss : 0.1784223383588522\n",
      "Epoch: 333  | loss : 0.1783645960687785\n",
      "Epoch: 334  | loss : 0.17830697675947407\n",
      "Epoch: 335  | loss : 0.17824947836324684\n",
      "Epoch: 336  | loss : 0.1781920989921401\n",
      "Epoch: 337  | loss : 0.17813483693573395\n",
      "Epoch: 338  | loss : 0.17807769065884096\n",
      "Epoch: 339  | loss : 0.1780206587990992\n",
      "Epoch: 340  | loss : 0.1779637401644633\n",
      "Epoch: 341  | loss : 0.17790693373060001\n",
      "Epoch: 342  | loss : 0.17785023863818186\n",
      "Epoch: 343  | loss : 0.17779365419009135\n",
      "Epoch: 344  | loss : 0.17773717984852716\n",
      "Epoch: 345  | loss : 0.17768081523201926\n",
      "Epoch: 346  | loss : 0.17762456011235103\n",
      "Epoch: 347  | loss : 0.17756841441139282\n",
      "Epoch: 348  | loss : 0.1775123781978409\n",
      "Epoch: 349  | loss : 0.17745645168386956\n",
      "Epoch: 350  | loss : 0.17740063522169236\n",
      "Epoch: 351  | loss : 0.1773449293000335\n",
      "Epoch: 352  | loss : 0.17728933454050913\n",
      "Epoch: 353  | loss : 0.17723385169392153\n",
      "Epoch: 354  | loss : 0.1771784816364616\n",
      "Epoch: 355  | loss : 0.1771232253658258\n",
      "Epoch: 356  | loss : 0.17706808399724086\n",
      "Epoch: 357  | loss : 0.1770130587594019\n",
      "Epoch: 358  | loss : 0.1769581509903253\n",
      "Epoch: 359  | loss : 0.17690336213311\n",
      "Epoch: 360  | loss : 0.1768486937316164\n",
      "Epoch: 361  | loss : 0.17679414742605867\n",
      "Epoch: 362  | loss : 0.17673972494851392\n",
      "Epoch: 363  | loss : 0.17668542811835\n",
      "Epoch: 364  | loss : 0.1766312588375719\n",
      "Epoch: 365  | loss : 0.1765772190860936\n",
      "Epoch: 366  | loss : 0.17652331091693152\n",
      "Epoch: 367  | loss : 0.17646953645132998\n",
      "Epoch: 368  | loss : 0.17641589787381667\n",
      "Epoch: 369  | loss : 0.17636239742719556\n",
      "Epoch: 370  | loss : 0.17630903740747944\n",
      "Epoch: 371  | loss : 0.17625582015876967\n",
      "Epoch: 372  | loss : 0.17620274806808622\n",
      "Epoch: 373  | loss : 0.17614982356015543\n",
      "Epoch: 374  | loss : 0.17609704909216187\n",
      "Epoch: 375  | loss : 0.17604442714847174\n",
      "Epoch: 376  | loss : 0.17599196023533256\n",
      "Epoch: 377  | loss : 0.17593965087556251\n",
      "Epoch: 378  | loss : 0.17588750160323158\n",
      "Epoch: 379  | loss : 0.17583551495834868\n",
      "Epoch: 380  | loss : 0.17578369348156112\n",
      "Epoch: 381  | loss : 0.17573203970887635\n",
      "Epoch: 382  | loss : 0.17568055616641748\n",
      "Epoch: 383  | loss : 0.17562924536521995\n",
      "Epoch: 384  | loss : 0.17557810979608576\n",
      "Epoch: 385  | loss : 0.1755271519244964\n",
      "Epoch: 386  | loss : 0.175476374185606\n",
      "Epoch: 387  | loss : 0.17542577897931855\n",
      "Epoch: 388  | loss : 0.17537536866546163\n",
      "Epoch: 389  | loss : 0.17532514555907128\n",
      "Epoch: 390  | loss : 0.17527511192579356\n",
      "Epoch: 391  | loss : 0.1752252699774166\n",
      "Epoch: 392  | loss : 0.17517562186754537\n",
      "Epoch: 393  | loss : 0.17512616968742367\n",
      "Epoch: 394  | loss : 0.17507691546192183\n",
      "Epoch: 395  | loss : 0.17502786114568986\n",
      "Epoch: 396  | loss : 0.1749790086194949\n",
      "Epoch: 397  | loss : 0.17493035968674314\n",
      "Epoch: 398  | loss : 0.1748819160702012\n",
      "Epoch: 399  | loss : 0.17483367940891886\n",
      "Epoch: 400  | loss : 0.17478565125536322\n",
      "Epoch: 401  | loss : 0.1747378330727698\n",
      "Epoch: 402  | loss : 0.17469022623271507\n",
      "Epoch: 403  | loss : 0.17464283201291514\n",
      "Epoch: 404  | loss : 0.1745956515952544\n",
      "Epoch: 405  | loss : 0.17454868606404803\n",
      "Epoch: 406  | loss : 0.17450193640453868\n",
      "Epoch: 407  | loss : 0.1744554035016289\n",
      "Epoch: 408  | loss : 0.17440908813885123\n",
      "Epoch: 409  | loss : 0.17436299099757246\n",
      "Epoch: 410  | loss : 0.1743171126564338\n",
      "Epoch: 411  | loss : 0.17427145359102292\n",
      "Epoch: 412  | loss : 0.17422601417377195\n",
      "Epoch: 413  | loss : 0.17418079467408634\n",
      "Epoch: 414  | loss : 0.17413579525868833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 415  | loss : 0.17409101599217838\n",
      "Epoch: 416  | loss : 0.174046456837804\n",
      "Epoch: 417  | loss : 0.17400211765843085\n",
      "Epoch: 418  | loss : 0.17395799821770885\n",
      "Epoch: 419  | loss : 0.17391409818142228\n",
      "Epoch: 420  | loss : 0.1738704171190204\n",
      "Epoch: 421  | loss : 0.1738269545053149\n",
      "Epoch: 422  | loss : 0.17378370972233667\n",
      "Epoch: 423  | loss : 0.1737406820613439\n",
      "Epoch: 424  | loss : 0.17369787072496629\n",
      "Epoch: 425  | loss : 0.17365527482948065\n",
      "Epoch: 426  | loss : 0.17361289340720465\n",
      "Epoch: 427  | loss : 0.17357072540899743\n",
      "Epoch: 428  | loss : 0.17352876970685865\n",
      "Epoch: 429  | loss : 0.17348702509661218\n",
      "Epoch: 430  | loss : 0.17344549030066714\n",
      "Epoch: 431  | loss : 0.17340416397084385\n",
      "Epoch: 432  | loss : 0.1733630446912523\n",
      "Epoch: 433  | loss : 0.17332213098121926\n",
      "Epoch: 434  | loss : 0.1732814212982458\n",
      "Epoch: 435  | loss : 0.17324091404099148\n",
      "Epoch: 436  | loss : 0.17320060755227312\n",
      "Epoch: 437  | loss : 0.17316050012207143\n",
      "Epoch: 438  | loss : 0.17312058999053248\n",
      "Epoch: 439  | loss : 0.1730808753509604\n",
      "Epoch: 440  | loss : 0.17304135435279042\n",
      "Epoch: 441  | loss : 0.17300202510453638\n",
      "Epoch: 442  | loss : 0.1729628856767047\n",
      "Epoch: 443  | loss : 0.17292393410466914\n",
      "Epoch: 444  | loss : 0.17288516839149867\n",
      "Epoch: 445  | loss : 0.1728465865107365\n",
      "Epoch: 446  | loss : 0.17280818640911946\n",
      "Epoch: 447  | loss : 0.17276996600923994\n",
      "Epoch: 448  | loss : 0.1727319232121395\n",
      "Epoch: 449  | loss : 0.17269405589983755\n",
      "Epoch: 450  | loss : 0.17265636193778294\n",
      "Epoch: 451  | loss : 0.17261883917723636\n",
      "Epoch: 452  | loss : 0.1725814854575715\n",
      "Epoch: 453  | loss : 0.17254429860849993\n",
      "Epoch: 454  | loss : 0.1725072764522137\n",
      "Epoch: 455  | loss : 0.17247041680544842\n",
      "Epoch: 456  | loss : 0.17243371748146172\n",
      "Epoch: 457  | loss : 0.1723971762919316\n",
      "Epoch: 458  | loss : 0.17236079104876978\n",
      "Epoch: 459  | loss : 0.1723245595658535\n",
      "Epoch: 460  | loss : 0.17228847966067606\n",
      "Epoch: 461  | loss : 0.17225254915591537\n",
      "Epoch: 462  | loss : 0.1722167658809208\n",
      "Epoch: 463  | loss : 0.17218112767312532\n",
      "Epoch: 464  | loss : 0.17214563237937522\n",
      "Epoch: 465  | loss : 0.17211027785718688\n",
      "Epoch: 466  | loss : 0.1720750619759297\n",
      "Epoch: 467  | loss : 0.17203998261793407\n",
      "Epoch: 468  | loss : 0.17200503767953274\n",
      "Epoch: 469  | loss : 0.1719702250720316\n",
      "Epoch: 470  | loss : 0.1719355427226153\n",
      "Epoch: 471  | loss : 0.1719009885751909\n",
      "Epoch: 472  | loss : 0.17186656059116723\n",
      "Epoch: 473  | loss : 0.17183225675017927\n",
      "Epoch: 474  | loss : 0.17179807505075328\n",
      "Epoch: 475  | loss : 0.1717640135109201\n",
      "Epoch: 476  | loss : 0.1717300701687749\n",
      "Epoch: 477  | loss : 0.17169624308299017\n",
      "Epoch: 478  | loss : 0.17166253033328116\n",
      "Epoch: 479  | loss : 0.1716289300208271\n",
      "Epoch: 480  | loss : 0.17159544026864998\n",
      "Epoch: 481  | loss : 0.1715620592219551\n",
      "Epoch: 482  | loss : 0.17152878504843383\n",
      "Epoch: 483  | loss : 0.1714956159385311\n",
      "Epoch: 484  | loss : 0.17146255010568068\n",
      "Epoch: 485  | loss : 0.17142958578650833\n",
      "Epoch: 486  | loss : 0.17139672124100694\n",
      "Epoch: 487  | loss : 0.17136395475268754\n",
      "Epoch: 488  | loss : 0.17133128462869912\n",
      "Epoch: 489  | loss : 0.17129870919993187\n",
      "Epoch: 490  | loss : 0.17126622682109469\n",
      "Epoch: 491  | loss : 0.17123383587077623\n",
      "Epoch: 492  | loss : 0.17120153475148356\n",
      "Epoch: 493  | loss : 0.1711693218896693\n",
      "Epoch: 494  | loss : 0.17113719573574027\n",
      "Epoch: 495  | loss : 0.17110515476405116\n",
      "Epoch: 496  | loss : 0.17107319747289051\n",
      "Epoch: 497  | loss : 0.17104132238444997\n",
      "Epoch: 498  | loss : 0.1710095280447865\n",
      "Epoch: 499  | loss : 0.17097781302377477\n"
     ]
    }
   ],
   "source": [
    "# struktur ANN\n",
    "input_layer = len(X[0])\n",
    "hidden_layer = 5\n",
    "output_layer = 3\n",
    "epoch = 500 # 500\n",
    "lr = .7\n",
    "Nguyen_widrow = True\n",
    "\n",
    "# training\n",
    "w_hidden, b_hidden, w_output, b_output, loss_values, acc_values = model_fit(hidden_layer, input_layer, output_layer, x_train, y_train, epoch, Nguyen_widrow)\n",
    "\n",
    "# testing\n",
    "accuracy, o_predict, o_predict2 = predict(x_test, w_hidden, b_hidden, w_output, b_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3G7PBtbqnHNr",
    "outputId": "add41c89-6865-40cd-c808-bb871dc9d4de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 1], [1, 0, 0], [0, 1, 0], [0, 0, 1], [0, 0, 1], [0, 1, 0], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0], [1, 0, 0], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [0, 0, 1], [1, 0, 0], [0, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1], [0, 0, 1], [1, 0, 0], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 0], [0, 0, 1], [1, 0, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1], [0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 0, 1], [1, 0, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [1, 0, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 0, 1], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 0, 1], [0, 1, 0], [0, 0, 1], [1, 0, 0], [0, 1, 0], [0, 0, 1], [0, 0, 1], [0, 1, 0]]\n",
      "[[1.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [1.0, 0.0, 1.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [0.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 1.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, 1.0], [0.0, 1.0, 0.0], [0.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [0.0, 1.0, 1.0], [1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [0.0, 1.0, 0.0]]\n",
      "[[10, 2, 6], [0, 42, 1], [4, 2, 26]]\n",
      "83.87096774193549\n",
      "78.15999138673556\n",
      "80.50693268084572\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "print(y_test)\n",
    "print(o_predict)\n",
    "# cm = multilabel_confusion_matrix(y_test, o_predict)\n",
    "# cma = multilabel_confusion_matrix(y_test, o_predict)\n",
    "# print(cma)\n",
    "\n",
    "temp = 0\n",
    "cm = [[0,0,0],[0,0,0],[0,0,0]]\n",
    "for i,y in enumerate(y_test):\n",
    "  if o_predict2[i].tolist().index(max(o_predict2[i]))==0: pred=[1,0,0]\n",
    "  elif o_predict2[i].tolist().index(max(o_predict2[i]))==1: pred=[0,1,0]\n",
    "  elif o_predict2[i].tolist().index(max(o_predict2[i]))==2: pred=[0,0,1]\n",
    "\n",
    "  if y_test[i]==[1,0,0] and pred==[1,0,0]: cm[0][0]+=1\n",
    "  elif y_test[i]==[1,0,0] and pred==[0,1,0]: cm[0][1]+=1\n",
    "  elif y_test[i]==[1,0,0] and pred==[0,0,1]: cm[0][2]+=1\n",
    "  elif y_test[i]==[0,1,0] and pred==[1,0,0]: cm[1][0]+=1\n",
    "  elif y_test[i]==[0,1,0] and pred==[0,1,0]: cm[1][1]+=1\n",
    "  elif y_test[i]==[0,1,0] and pred==[0,0,1]: cm[1][2]+=1\n",
    "  elif y_test[i]==[0,0,1] and pred==[1,0,0]: cm[2][0]+=1\n",
    "  elif y_test[i]==[0,0,1] and pred==[0,1,0]: cm[2][1]+=1\n",
    "  elif y_test[i]==[0,0,1] and pred==[0,0,1]: cm[2][2]+=1\n",
    "\n",
    "print(cm)\n",
    "\n",
    "accuracy = (cm[0][0] + cm[1][1] + cm[2][2])/ len(y_test)\n",
    "precision = ((cm[0][0]/(cm[0][0] + cm[0][1] + cm[0][2])) + (cm[1][1]/(cm[1][1] + cm[1][0] + cm[1][2])) + (cm[2][2]/(cm[2][2] + cm[2][0] + cm[2][1])))/3\n",
    "recall = ((cm[0][0]/(cm[0][0] + cm[1][0] + cm[2][0])) + (cm[1][1]/(cm[1][1] + cm[0][1] + cm[2][1])) + (cm[2][2]/(cm[2][2] + cm[0][2] + cm[1][2])))/3\n",
    "\n",
    "print(accuracy*100)\n",
    "print(precision*100)\n",
    "print(recall*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "DUq3oQOwRbpz",
    "outputId": "86c9f3c1-3892-4aac-a9b5-92c3a8980091"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot1 = plt.figure(1)\n",
    "plt.plot(loss_values)\n",
    "plt.show()\n",
    "\n",
    "plot1 = plt.figure(1)\n",
    "plt.plot(acc_values)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Backpro - 5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
